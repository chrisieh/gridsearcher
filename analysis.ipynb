{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import glob\n",
    "import json\n",
    "import gc\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def rej_fixed_eff(truth, score, weight, efficiencies):\n",
    "    fpr, tpr, thr = roc_curve(truth, score, sample_weight=weight)\n",
    "    nonzero = (fpr != 0)\n",
    "    eff = tpr[nonzero]\n",
    "    rej = 1.0 / fpr[nonzero]\n",
    "    \n",
    "    interpol = interp1d(eff, rej, copy=False)\n",
    "    return interpol(efficiencies)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KS test is on hold\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def steps(x, y, inp):\n",
    "    x = np.r_[-np.inf, x]\n",
    "    y = np.r_[0.0, y]\n",
    "    idx = np.searchsorted(x, inp, \"right\") - 1\n",
    "    return y[idx]\n",
    "\n",
    "def ks_2samp_weights(data1, data2, weight1, weight2):\n",
    "    # Sort\n",
    "    sarg1 = np.argsort(data1)\n",
    "    sarg2 = np.argsort(data2)\n",
    "    \n",
    "    data1 = data1[sarg1]\n",
    "    weight1 = weight1[sarg1]\n",
    "    \n",
    "    data2 = data2[sarg2]\n",
    "    weight2 = weight2[sarg2]\n",
    "    \n",
    "    # Calculate cdf\n",
    "    cdf1 = np.cumsum(weight1)\n",
    "    cdf1 /= cdf1[-1]\n",
    "    cdf2 = np.cumsum(weight2)\n",
    "    cdf2 /= cdf2[-1]\n",
    "    \n",
    "    # Calculate all the ecdf values   \n",
    "    x_all = np.concatenate([data1, data2])\n",
    "    \n",
    "    y1 = steps(data1, cdf1, x_all)\n",
    "    y2 = steps(data2, cdf2, x_all)\n",
    "    \n",
    "    d = np.max(np.absolute(y1 - y2))\n",
    "    \n",
    "    s1 = np.sum(weight1)\n",
    "    s2 = np.sum(weight2)\n",
    "    \n",
    "    en = np.sqrt(s1) * np.sqrt(s2) / np.sqrt(s1 + s2)\n",
    "    \n",
    "    try:\n",
    "        prob = distributions.kstwobign.sf((en + 0.12 + 0.11 / en) * d)\n",
    "    except:\n",
    "        prob = 1.0\n",
    "    \n",
    "    return d, prob    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tid_1pvars = [\"TauJets.centFrac\", \"TauJets.etOverPtLeadTrk\",\n",
    "              \"TauJets.innerTrkAvgDist\", \"TauJets.absipSigLeadTrk\",\n",
    "              \"TauJets.SumPtTrkFrac\", \"TauJets.ChPiEMEOverCaloEME\",\n",
    "              \"TauJets.EMPOverTrkSysP\", \"TauJets.ptRatioEflowApprox\",\n",
    "              \"TauJets.mEflowApprox\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = pd.read_hdf(\"samples/train.h5\", columns=tid_1pvars + [\"weight\", \"is_sig\"])\n",
    "\n",
    "train_weights = train_sample[\"weight\"].get_values()\n",
    "train_is_sig = train_sample[\"is_sig\"].get_values()\n",
    "dtrain = xgb.DMatrix(train_sample[tid_1pvars], label=train_sample[\"is_sig\"], weight=train_sample[\"weight\"])\n",
    "\n",
    "%xdel train_sample\n",
    "gc.collect()\n",
    "\n",
    "test_sample = pd.read_hdf(\"samples/test.h5\", columns=tid_1pvars + [\"weight\", \"is_sig\"])\n",
    "\n",
    "test_weights = test_sample[\"weight\"].get_values()\n",
    "test_is_sig = test_sample[\"is_sig\"].get_values()\n",
    "dtest = xgb.DMatrix(test_sample[tid_1pvars], label=test_sample[\"is_sig\"], weight=test_sample[\"weight\"])\n",
    "\n",
    "%xdel test_sample\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_analysis(filename):\n",
    "    # Collection of metrics\n",
    "    ret = {}\n",
    "    \n",
    "    # Load stuff\n",
    "    with open(filename) as f:\n",
    "        model_desc = json.load(f)\n",
    "    \n",
    "    bst = xgb.Booster(model_file=\"models/{}.model\".format(model_desc[\"identifier\"]))\n",
    "    ret[\"best_iteration\"] = int(bst.attributes()[\"best_iteration\"])\n",
    "    \n",
    "    train_scores = bst.predict(dtrain, ntree_limit=ret[\"best_iteration\"])\n",
    "    test_scores = bst.predict(dtest, ntree_limit=ret[\"best_iteration\"])\n",
    "    \n",
    "    rej30, rej50, rej70 = rej_fixed_eff(test_is_sig, test_scores, test_weights, [0.3, 0.5, 0.7])\n",
    "    \n",
    "    ret[\"id\"] = model_desc[\"identifier\"]\n",
    "    ret[\"rej30\"] = rej30\n",
    "    ret[\"rej50\"] = rej50\n",
    "    ret[\"rej70\"] = rej70\n",
    "\n",
    "    \n",
    "    ret.update(model_desc[\"config\"])\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed = []\n",
    "for model_desc in glob.glob(\"models/*.json\"):\n",
    "    with open(model_desc) as f:\n",
    "        desc = json.load(f)\n",
    "    if desc[\"processed\"]:\n",
    "        processed.append(model_desc)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_desc in processed:\n",
    "    ret = do_analysis(model_desc)\n",
    "    print(ret)\n",
    "    rets.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.sort_values(\"rej50\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
