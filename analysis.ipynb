{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import glob\n",
    "import json\n",
    "import gc\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def rej_fixed_eff(truth, score, weight, efficiencies):\n",
    "    fpr, tpr, thr = roc_curve(truth, score, sample_weight=weight)\n",
    "    nonzero = (fpr != 0)\n",
    "    eff = tpr[nonzero]\n",
    "    rej = 1.0 / fpr[nonzero]\n",
    "    \n",
    "    interpol = interp1d(eff, rej, copy=False)\n",
    "    return interpol(efficiencies)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def steps(x, y, inp):\n",
    "    x = np.r_[-np.inf, x]\n",
    "    y = np.r_[0.0, y]\n",
    "    idx = np.searchsorted(x, inp, \"right\") - 1\n",
    "    return y[idx]\n",
    "\n",
    "def ks_2samp_weights(data1, data2, weight1, weight2):\n",
    "    # Sort\n",
    "    sarg1 = np.argsort(data1)\n",
    "    sarg2 = np.argsort(data2)\n",
    "    \n",
    "    data1 = data1[sarg1]\n",
    "    weight1 = weight1[sarg1]\n",
    "    \n",
    "    data2 = data2[sarg2]\n",
    "    weight2 = weight2[sarg2]\n",
    "    \n",
    "    # Calculate cdf\n",
    "    cdf1 = np.cumsum(weight1)\n",
    "    cdf1 /= cdf1[-1]\n",
    "    cdf2 = np.cumsum(weight2)\n",
    "    cdf2 /= cdf2[-1]\n",
    "    \n",
    "    # Calculate all the ecdf values   \n",
    "    x_all = np.concatenate([data1, data2])\n",
    "    \n",
    "    y1 = steps(data1, cdf1, x_all)\n",
    "    y2 = steps(data2, cdf2, x_all)\n",
    "    \n",
    "    d = np.max(np.absolute(y1 - y2))\n",
    "    \n",
    "    s1 = np.sum(weight1)\n",
    "    s2 = np.sum(weight2)\n",
    "    \n",
    "    en = np.sqrt(s1) * np.sqrt(s2) / np.sqrt(s1 + s2)\n",
    "    \n",
    "    try:\n",
    "        prob = distributions.kstwobign.sf((en + 0.12 + 0.11 / en) * d)\n",
    "    except:\n",
    "        prob = 1.0\n",
    "    \n",
    "    \n",
    "    return d, prob    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tid_1pvars = [\"TauJets.centFrac\", \"TauJets.etOverPtLeadTrk\",\n",
    "              \"TauJets.innerTrkAvgDist\", \"TauJets.absipSigLeadTrk\",\n",
    "              \"TauJets.SumPtTrkFrac\", \"TauJets.ChPiEMEOverCaloEME\",\n",
    "              \"TauJets.EMPOverTrkSysP\", \"TauJets.ptRatioEflowApprox\",\n",
    "              \"TauJets.mEflowApprox\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = pd.read_hdf(\"samples/train.h5\", columns=tid_1pvars + [\"weight\", \"is_sig\"])\n",
    "\n",
    "train_weights = train_sample[\"weight\"].get_values()\n",
    "train_is_sig = train_sample[\"is_sig\"].get_values()\n",
    "dtrain = xgb.DMatrix(train_sample[tid_1pvars], label=train_sample[\"is_sig\"], weight=train_sample[\"weight\"])\n",
    "\n",
    "%xdel train_sample\n",
    "gc.collect()\n",
    "\n",
    "test_sample = pd.read_hdf(\"samples/test.h5\", columns=tid_1pvars + [\"weight\", \"is_sig\"])\n",
    "\n",
    "test_weights = test_sample[\"weight\"].get_values()\n",
    "test_is_sig = test_sample[\"is_sig\"].get_values()\n",
    "dtest = xgb.DMatrix(test_sample[tid_1pvars], label=test_sample[\"is_sig\"], weight=test_sample[\"weight\"])\n",
    "\n",
    "%xdel test_sample\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_analysis(filename):\n",
    "    # Load stuff\n",
    "    with open(filename) as f:\n",
    "        model_desc = json.load(f)\n",
    "    \n",
    "    bst = xgb.Booster(model_file=\"models/{}.model\".format(model_desc[\"identifier\"]))\n",
    "    train_scores = bst.predict(dtrain, ntree_limit=100)\n",
    "    test_scores = bst.predict(dtest, ntree_limit=100)\n",
    "    \n",
    "    rej30, rej50, rej70 = rej_fixed_eff(test_is_sig, test_scores, test_weights, [0.3, 0.5, 0.7])\n",
    "    \n",
    "    sig_train = (train_is_sig == 1)\n",
    "    bkg_train = np.logical_not(sig_train)\n",
    "    sig_test = (test_is_sig == 1)\n",
    "    bkg_test = np.logical_not(sig_test)\n",
    "    \n",
    "    dsig, pvalsig = ks_2samp_weights(train_scores[sig_train], test_scores[sig_test], train_weights[sig_train], test_weights[sig_test])\n",
    "    dbkg, pvalbkg = ks_2samp_weights(train_scores[bkg_train], test_scores[bkg_test], train_weights[bkg_train], test_weights[bkg_test])\n",
    "    print(\"d: {}, pval: {}\".format(dsig, pvalsig))\n",
    "    print(\"d: {}, pval: {}\".format(dbkg, pvalbkg))\n",
    "    dsig, pvalsig = ks_2samp(train_scores[sig_train], test_scores[sig_test], train_weights[sig_train], test_weights[sig_test])\n",
    "    dbkg, pvalbkg = ks_2samp(train_scores[bkg_train], test_scores[bkg_test], train_weights[bkg_train], test_weights[bkg_test])\n",
    "    print(\"d: {}, pval: {}\".format(dsig, pvalsig))\n",
    "    print(\"d: {}, pval: {}\".format(dbkg, pvalbkg))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(model_desc[\"identifier\"])\n",
    "    print(\"{}, {}, {}\".format(rej30, rej50, rej70))\n",
    "    \n",
    "    \n",
    "    # Collection of different metrics\n",
    "    metrics = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed = []\n",
    "for model_desc in glob.glob(\"models/*.json\"):\n",
    "    with open(model_desc) as f:\n",
    "        desc = json.load(f)\n",
    "    if desc[\"processed\"]:\n",
    "        processed.append(model_desc)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0004\n",
      "179.557705114, 70.7886689759, 31.0027263281\n",
      "d: 0.00096070766449, pval: 1.0\n",
      "d: 0.000961184501648, pval: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d19867fdc08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdo_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f31a86c223e4>\u001b[0m in \u001b[0;36mdo_analysis\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"models/{}.model\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"identifier\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/atlass01.physik.uni-bonn.de/user/cdeutsch/.opt/venv/tauid/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf)\u001b[0m\n\u001b[1;32m    957\u001b[0m                                           \u001b[0moption_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_desc in processed:\n",
    "    do_analysis(model_desc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
